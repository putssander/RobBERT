{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Demo of RobBERT for Dutch named entity recognition\n",
    "We use a [RobBERT (Delobelle et al., 2020)](https://arxiv.org/abs/2001.06286) model for NER.\n",
    "\n",
    "**Dependencies**\n",
    "- tokenizers\n",
    "- torch\n",
    "- transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load our RobBERT model that was pretrained on OSCAR and finetuned on Dutch named entity recognition. We also load in RobBERT's tokenizer.\n",
    "\n",
    "Because we only want to get results, we have to disable dropout etc. So we add `model.eval()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RobBERT model loaded\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import RobertaTokenizer, RobertaForTokenClassification\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained('pdelobelle/robbert-v2-dutch-ner')\n",
    "model = RobertaForTokenClassification.from_pretrained('pdelobelle/robbert-v2-dutch-ner', return_dict=True)\n",
    "model.eval()\n",
    "print(\"RobBERT model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%% \n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids:\n",
      "\ttensor([[    0,  6079,   499,    38,     5, 13292,    11,  6422,     8,  7010,\n",
      "             9,  2617,     4,     2,     1],\n",
      "        [    0, 25907,   129,  1283,     8,  3971,   113,    28,   118,    71,\n",
      "           435,    38, 27600,     4,     2],\n",
      "        [    0,  9396,    89,     9,   797,  2877,    22,    11,     5,  4290,\n",
      "           445,     4,     2,     1,     1],\n",
      "        [    0,  7751,     6,    74,   458,    12,  3663, 14334,   342,     4,\n",
      "             2,     1,     1,     1,     1]])\n",
      "attention_mask:\n",
      "\ttensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]])\n",
      "Tokens:\n",
      "\t['<s>', 'Jan', 'Ġging', 'Ġnaar', 'Ġde', 'Ġbakker', 'Ġin', 'ĠLeuven', 'Ġen', 'Ġkocht', 'Ġeen', 'Ġbrood', '.', '</s>', '<pad>']\n",
      "\t['<s>', 'Bedrijven', 'Ġzoals', 'ĠGoogle', 'Ġen', 'ĠMicrosoft', 'Ġdoen', 'Ġook', 'Ġheel', 'Ġveel', 'Ġonderzoek', 'Ġnaar', 'ĠNLP', '.', '</s>']\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer.batch_encode_plus(\n",
    "    [\"Jan ging naar de bakker in Leuven en kocht een brood.\",\n",
    "     \"Bedrijven zoals Google en Microsoft doen ook heel veel onderzoek naar NLP.\",\n",
    "     \"Men moet een gegeven paard niet in de bek kijken.\",\n",
    "     \"Hallo, mijn naam is RobBERT.\"],\n",
    "    return_tensors=\"pt\", padding=True)\n",
    "for key, value in inputs.items():\n",
    "    print(\"{}:\\n\\t{}\".format(key, value))\n",
    "print(\"Tokens:\\n\\t{}\".format(tokenizer.convert_ids_to_tokens(inputs['input_ids'][0]) ))\n",
    "print(\"\\t{}\".format(tokenizer.convert_ids_to_tokens(inputs['input_ids'][1]) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "In our model config, we stored what labels we use. \n",
    "We can load these in and automatically convert our predictions to a human-readable format.\n",
    "For reference, we have 4 types of named entities:\n",
    "\n",
    "- PER\n",
    "- LOC\n",
    "- ORG\n",
    "- MISC\n",
    "\n",
    "And we mark the first token with `B-` and then we mark a continuation with `I-`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'B-PER', 1: 'B-ORG', 2: 'B-LOC', 3: 'B-MISC', 4: 'I-PER', 5: 'I-ORG', 6: 'I-LOC', 7: 'I-MISC', 8: 'O'}\n"
     ]
    }
   ],
   "source": [
    "print(model.config.id2label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Ok, let's do some predictions! Since we have a batch of 4 sentences, we can do this in one batch—as long as it fits on your GPU.\n",
    "\n",
    "_If the formatting of this fails, you can try to zoom out or make the window wider_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 0\n",
      "<s>         Jan         Ġging       Ġnaar       Ġde         Ġbakker     Ġin         ĠLeuven     Ġen         Ġkocht      Ġeen        Ġbrood      .           </s>        <pad>       \n",
      "\n",
      "O           B-PER       O           O           O           O           O           B-LOC       O           O           O           O           O           O           O           \n",
      "\n",
      "Sentence 1\n",
      "<s>         Bedrijven   Ġzoals      ĠGoogle     Ġen         ĠMicrosoft  Ġdoen       Ġook        Ġheel       Ġveel       Ġonderzoek  Ġnaar       ĠNLP        .           </s>        \n",
      "\n",
      "O           O           O           B-ORG       O           B-ORG       O           O           O           O           O           O           B-MISC      O           O           \n",
      "\n",
      "Sentence 2\n",
      "<s>         Men         Ġmoet       Ġeen        Ġgegeven    Ġpaard      Ġniet       Ġin         Ġde         Ġbek        Ġkijken     .           </s>        <pad>       <pad>       \n",
      "\n",
      "O           O           O           O           O           O           O           O           O           O           O           O           O           O           O           \n",
      "\n",
      "Sentence 3\n",
      "<s>         Hallo       ,           Ġmijn       Ġnaam       Ġis         ĠRob        BER         T           .           </s>        <pad>       <pad>       <pad>       <pad>       \n",
      "\n",
      "O           O           O           O           O           O           B-PER       I-PER       I-PER       O           O           O           O           O           I-PER       \n",
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    results = model(**inputs)\n",
    "    for i, input in enumerate(inputs['input_ids']):\n",
    "        print(f\"Sentence {i}\")\n",
    "        [print(\"{:12}\".format(token), end=\"\") for token in tokenizer.convert_ids_to_tokens(input) ]\n",
    "        print('\\n')\n",
    "        [print(\"{:12}\".format(model.config.id2label[item.item()]), end=\"\") for item in results.logits[i].argmax(axis=1)]\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Ok, this works nicely! We have 'Jan', 'Leuven' and companies like 'Google' that are all labeled correctly. \n",
    "In addition, RobBERT consists of multiple tokens (perhaps we should have added one with it's name) and that works with the `I-` token as well.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
